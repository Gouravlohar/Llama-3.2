{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install groq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jj0FFI8i12H0",
        "outputId": "a4ae30ff-53ca-4fca-ad27-2307c7d87b4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting groq\n",
            "  Downloading groq-0.11.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from groq) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from groq)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from groq) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from groq) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq) (2024.8.30)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->groq)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->groq)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq) (2.23.4)\n",
            "Downloading groq-0.11.0-py3-none-any.whl (106 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.5/106.5 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: h11, httpcore, httpx, groq\n",
            "Successfully installed groq-0.11.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NwaptrK60eFp",
        "outputId": "f883e63e-bb4d-4370-89e1-cf77bc581c3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imagine you have a lemonade stand, and you want to use a special machine (called a \"model\") to predict how many cups of lemonade you'll sell on a sunny day versus a cloudy day.\n",
            "\n",
            "The machine is very smart and can learn from past sales data, like how many cups you sold on sunny days and cloudy days. But, to make sure the machine is working correctly and giving accurate predictions, you need to:\n",
            "\n",
            "1. **Feed it the right food (data)**: You need to collect and clean up the sales data so the machine can learn from it.\n",
            "2. **Teach it what to do**: You need to explain to the machine what to do with the data, like \"look for sunny days\" and \"sell more lemonade on those days.\"\n",
            "3. **Test it**: You need to check if the machine's predictions are correct by comparing them to real-life sales data.\n",
            "4. **Keep it updated**: You need to make sure the machine is using the latest sales data so its predictions stay accurate.\n",
            "\n",
            "This is kind of like \"Lemonade Stand Ops\" (LSOps). But, when we're working with big computers and complex machines (like AI models), we call it **MLOps** (Machine Learning Operations).\n",
            "\n",
            "MLOps is like a recipe to make sure our machine learning models are working correctly, giving accurate predictions, and helping us make better decisions. It involves a team of people working together to:\n",
            "\n",
            "* Collect and clean data\n",
            "* Train and test the machine learning model\n",
            "* Deploy the model to a real-world application\n",
            "* Monitor and update the model to keep it accurate\n",
            "\n",
            "Just like how you need to take care of your lemonade stand to make sure it runs smoothly, we need MLOps to take care of our machine learning models and ensure they're working correctly and making accurate predictions."
          ]
        }
      ],
      "source": [
        "from google.colab import userdata\n",
        "GROQ_API_KEY=userdata.get('GROQ_API_KEY')\n",
        "from groq import Groq\n",
        "\n",
        "\n",
        "client = Groq(api_key=GROQ_API_KEY)\n",
        "completion = client.chat.completions.create(\n",
        "    model=\"llama-3.2-90b-text-preview\",\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \" Why MLops is required. Explain me like 10 years old child\"\n",
        "        }\n",
        "    ],\n",
        "    temperature=1,\n",
        "    max_tokens=1024,\n",
        "    top_p=1,\n",
        "    stream=True,\n",
        "    stop=None,\n",
        ")\n",
        "\n",
        "for chunk in completion:\n",
        "    print(chunk.choices[0].delta.content or \"\", end=\"\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import base64\n",
        "from groq import Groq\n",
        "\n",
        "def image_to_base64(image_path):\n",
        "    \"\"\"Converts an image file to base64 encoding.\"\"\"\n",
        "    with open(image_path, \"rb\") as image_file:\n",
        "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
        "\n",
        "# Ensure you have set the GROQ_API_KEY in your Colab userdata\n",
        "client = Groq(api_key=userdata.get('GROQ_API_KEY'))\n",
        "\n",
        "# Specify the path of your local image\n",
        "image_path = \"/content/2.jpg\"\n",
        "\n",
        "# Load and encode your image\n",
        "image_base64 = image_to_base64(image_path)\n",
        "\n",
        "# Make the API request\n",
        "try:\n",
        "    completion = client.chat.completions.create(\n",
        "        model=\"llama-3.2-11b-vision-preview\",\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": [\n",
        "                    {\n",
        "                        \"type\": \"text\",\n",
        "                        \"text\": \"what is this?\"\n",
        "                    },\n",
        "                    {\n",
        "                        \"type\": \"image_url\",\n",
        "                        \"image_url\": {\n",
        "                            \"url\": f\"data:image/jpeg;base64,{image_base64}\"\n",
        "                        }\n",
        "                    }\n",
        "                ]\n",
        "            }\n",
        "        ],\n",
        "        temperature=1,\n",
        "        max_tokens=1024,\n",
        "        top_p=1,\n",
        "        stream=True,\n",
        "        stop=None,\n",
        "    )\n",
        "\n",
        "    # Process and print the response\n",
        "    for chunk in completion:\n",
        "        if chunk.choices and chunk.choices[0].delta and chunk.choices[0].delta.content:\n",
        "            print(chunk.choices[0].delta.content, end=\"\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tBbiKyrypsw",
        "outputId": "6d15a9b8-bc80-466b-f55a-0ba417ab7364"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The image depicts a modern office scene, featuring a robot and a server. The robot is positioned on the left side of the room, with its right hand raised and a speech bubble emanating from it that reads \"Database.\" The server, comprising multiple stacked panels, is situated on the right side of the room. The background of the image is blurred, but it appears to be an office setting with desks, chairs, and computers.\n",
            "\n",
            "*   **Robot:**\n",
            "    *   Located on the left side of the room\n",
            "    *   Right hand raised\n",
            "    *   Speech bubble with the word \"Database\"\n",
            "*   **Server:**\n",
            "    *   Positioned on the right side of the room\n",
            "    *   Comprises multiple stacked panels\n",
            "*   **Background:**\n",
            "    *   Blurred office setting\n",
            "    *   Desks, chairs, and computers visible"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4HOOtSXN3drU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}